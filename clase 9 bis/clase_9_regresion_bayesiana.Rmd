---
title: "Regresión Bayesiana"
author: "Juan Barriola, Azul Villanueva y Franco Mastelli"
date: "15 de Octubre de 2022"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
---

<style type="text/css">
div.main-container {
  max-width: 1600px;
  margin-left: auto;
  margin-right: auto;
}
</style>


```{r, message=FALSE}
# Carga de librerías
library(tidyverse)
library(tidymodels)
library(brms)
library(GGally)
```

En esta notebook desarrollaremos modelos de regresión clásica y bayesiana para explicar/predecir los salarios de los jugadores de la NBA para la temporada 2022-2023 en base a información de la temporada pasada.

# Datasets 

Trabajaremos con los datasets de salarios de la temporada 2022-2023 de la NBA y las estadísticas por partido de la temporada 2021-2022. La información se scrappeó de la página basketball-reference y la construcción estos datasets se encuentra en (link a la notebook).

Cargamos los datasets y realizamos un join entre ambos mediante el nombre del jugador

```{r}
# Salarios 2022-2023
salarios_nba = read_csv("../Fuentes/nba/salarios_nba_2023.csv")
# Estadísticas por partido 2021-2022
estadisticas_por_partido_nba = read_csv("../Fuentes/nba/estadisticas_por_partido_nba_2022.csv") %>%
  # Conservamos el primer tipo de posicion declarada
  mutate(Pos = str_remove(string = Pos, pattern = "\\-.*"))
# Realizamos un join entre ambas tablas mediante el nombre
nba_salarios_estadisticas_partido = salarios_nba %>% 
                            inner_join(y=estadisticas_por_partido_nba, on=jugador) %>% 
                            drop_na()

```
# Analisis exploratorios

Como se mencionó previamente, nuestro interés está en explicar la variable del salario anual. Usaremos pocas variables para mantener los modelos sencillos:

**Variable dependiente**

* salario: salario anual de la temporada 2022-23

**Variables independientes**

* PTS: puntos por partido en la temporada 2021-22
* Age: edad en años del jugador en la temporada 2021-22
* TRB: rebotes totales (ofensivos y defensivos) por partido en la temporada 2021-22

Realizamos primero un correlagrama entre las 4 variables numéricas

```{r}
nba_salarios_estadisticas_partido %>% 
  select(Age, PTS, TRB, salario) %>% 
  ggpairs(upper = list(continuous = wrap("cor", size = 3, hjust=0.5)), progress=FALSE) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position = "bottom") + 
  theme_bw() +
  labs(title='Correlograma variables continuas')
```

Observamos:

* Todas las variables presentan asimetría positica. Se destaca la distribución del salario con una asimetrìa muy fuerte

* Las tres variables presentan una correlación positiva con el salario. Los puntos por partido presentan una correlación fuerte (0.798) mientras que los rebotes totales por partido y la edad presentan valores de correlación más moderados


```{r}
ggplot(data = nba_salarios_estadisticas_partido, aes(x=Pos, y=salario, fill=Pos)) +
  geom_boxplot() +
  theme_bw()
```


# Modelo lineal clásico

Recordemos que el enfoque clásico postula parámetros fijos y desconocidos y un target aleatorio

$Y \sim N(\beta_0+\sum\limits_{i=1}^p{\beta_iX_i} , \sigma)$

Siendo $\beta_0, \beta_1,..., \beta_p,  \sigma$ los parámetros fijos y desconocidos que debemos estimar.

## Modelo simple

Realicemos un modelo de regresión simple para predecir el salario en función de los puntos por partido:

$Salario = \beta_0 + \beta_1 Puntos + \varepsilon$

En este caso vamos a estimar tres parámetros

```{r}
# Fiteamos el modelo
modelo_clasico_puntos = lm(data = nba_salarios_estadisticas_partido, formula = salario ~ PTS)
```

Observamos los valores de los coeficientes estimados junto con el p-valor del test de significatividad individual y los límites de los intervalos de confianza al 95%

```{r}
# Observamos los valores de los coeficientes estimados
coef_modelo_clasico_puntos = tidy(modelo_clasico_puntos, conf.int = TRUE)
coef_modelo_clasico_puntos
```

El valor de $\hat{\beta_1}$ indica que por cada punto por partido adicional el salario esperado aumenta en `r modelo_clasico_puntos$coefficients[2]` dólares.

El límite inferior del intervalo es `r coef_modelo_clasico_puntos %>% filter(term=='PTS') %>% select(conf.low) %>% as.numeric()` y el superior `r coef_modelo_clasico_puntos %>% filter(term=='PTS') %>% select(conf.high) %>% as.numeric()`

Observamos los valores de sigma y el p-valor del test de significatividad global

```{r}
# Observamos los valores de la evaluación global
glance(modelo_clasico_puntos)
```
## Modelo múltiple

Realicemos un modelo de regresión múltiple para predecir el salario en función de los puntos por partido, edad y rebotes totales por partido:

$Salario = \beta_0 + \beta_1 Puntos + \beta_2 Edad + \beta_3 RebotesTotales+ \varepsilon$

En este caso vamos a estimar cinco parámetros

```{r}
# Fiteamos el modelo
modelo_clasico_multiple = lm(data = nba_salarios_estadisticas_partido, formula = salario ~ PTS + Age + TRB)
```

Observamos los valores de los coeficientes estimados junto con el p-valor del test de significatividad individual y los límites de los intervalos de confianza al 95%

```{r}
# Observamos los valores de los coeficientes estimados
tidy(modelo_clasico_multiple, conf.int = TRUE)
```

Observamos los valores de sigma y el p-valor del test de significatividad global

```{r}
# Observamos los valores de la evaluación global
glance(modelo_clasico_multiple)
```
# Modelo Bayesiano

Recordemos que el enfoque bayesiano postula parámetros aleatorios para el mismo modelo:

$Y \sim N(\beta_0+\sum\limits_{i=1}^p{\beta_iX_i} , \sigma)$

Donde:

$\beta_0 \sim N(0,\tau_{\beta_0})$
$\beta_i \sim N(0,\tau_{\beta_i})$ para i entre 1 y p
$\sigma \sim Exp(\lambda)$

Siendo $\tau_{\beta_0}, \tau_{\beta_i}, \lambda$ fijos y propuestos por nosotros

## Paquete brms

Vamos a utilizar la implementación de modelos bayesianos de la librería **brms** (Bayesian Regression Models using Stan). El paper de esta librería se puede encontrar [aquí](https://cran.r-project.org/web/packages/brms/vignettes/brms_overview.pdf)

La función que vamos a utilizar es `brm()` la cual permite construir una gran variedad de modelos bayesianos. Algunos de sus parámetros más relevantes son: 

**Modelo**

* `formula`: la fórmula del modelo que queremos realizar

* `data`: dataset a utilizar

* `family`: distribución de la variable respuesta/target y función link. Por default se aplica la distribución gaussiana/normal

* `prior`: distribuciones prior de los parámetros

**Simulación**

* `init`: valores iniciales para el muestreo de los parámetros. Por default es random

* `chains`: cantidad de cadenas de Markov. Por default son 4

* `iter`: cantidad de iteraciones totales por cadena incluyendo warmup. Por default son 2000

* `warmup`: cantidad de iteraciones de warmup. Por default es iter/2

**Ejecución**

* `cores`: cantidad de núcleos a utilizar en la ejecución de las cadenas de manera paralelizada. Por default es 1.

* `seed`: semilla para reproducibilidad

## Modelo simple

Realicemos el mismo modelo simple con la configuración default de brms:

$Salario \sim N(\beta_0+\beta_1Puntos, \sigma)$

```{r, echo=TRUE, results='hide'}
regresion_bayesiana_simple <- brm(
  formula = salario ~ PTS,
  data = nba_salarios_estadisticas_partido,
  cores = 6,
  seed = 1992
)
```
Observemos un resumen del modelo usando la función `summary`

```{r}
# Vemos el resumen del modelo
summary(regresion_bayesiana_simple)
```
Lo primero que se observa es la configuración del modelo:

* La **familia** es gaussiana y las **funciones de link** para los parámetros $\mu$ y $\sigma$ son la función identidad

* La fórmula y dataset que definimos

* La configuración para el muestreo (draws) para el proceso de MCMC:
  
  * Hay 4 **cadenas**
  * Son 2000 **iteraciones** de las cuales 1000 son de **warmup** (por cadena)
  * En total son 4 cadenas cada una con 2000 iteraciones en total, dando un total de 8000 iteraciones. Como la mitad son iteraciones de warmup el **total de muestreos (draws) post warmup** es 4000. 

Luego podemos ver información de los parámetros de la población y de los parámetros especificos de la familia

```{r}
regresion_bayesiana_simple$fit
```
Con el comando `plot` podemos observar la distribución a posteriori y el proceso de muestreo de las cadenas de cada parámetro. 

```{r}
plot(regresion_bayesiana_simple)
```

## Tidybayes

```{r}
library(tidybayes)
```

```{r}
get_variables(regresion_bayesiana_simple)
```


```{r}
regresion_bayesiana_simple %>%
  spread_draws(b_Intercept, b_PTS, sigma)
```

```{r}
regresion_bayesiana_simple %>%
  gather_draws(b_Intercept, b_PTS, sigma) %>% 
  mean_qi()
```



```{r}
regresion_bayesiana_simple %>%
  gather_draws(b_Intercept, b_PTS, sigma) %>% 
  summarise_draws()
```



```{r}
regresion_bayesiana_simple %>% 
  gather_draws(b_Intercept, b_PTS, sigma) %>% 
  ggplot(aes(x=.iteration, y=.value, color=factor(.chain))) +
  geom_line() +
  facet_wrap(facets = ~.variable, ncol=1,scales = 'free') +
  scale_color_discrete() +
  theme_bw()

```

## Modelo simple: Priors

### Priors adecuadas

### Priors inadecuadas

## Modelo multiple

Realicemos un primer modelo con la configuración default

```{r, echo=TRUE, results='hide'}
regresion_bayesiana_multiple <- brm(
  formula = salario ~ PTS + Age + TRB,
  data = nba_salarios_estadisticas_partido,
  cores = 6,
  seed = 1992
)
```

```{r}
summary(regresion_bayesiana_multiple)
```
## Modelo categóricas

# Experimentos

## Sin warm-up

¿Qué pasa con nuestro modelo si no realizamos warmup?

```{r, echo=TRUE, results='hide'}
regresion_bayesiana_no_warmup <- brm(
  formula = salario ~ PTS,
  data = nba_salarios_estadisticas_partido,
  warmup = 0,
  cores = 6,
  seed = 1992
)
```
```{r}
summary(regresion_bayesiana_no_warmup)
```
```{r}
plot(regresion_bayesiana_no_warmup, ask = FALSE)
```

## Poco warm-up

¿Qué pasa con nuestro modelo si realizamos un warmup muy pequeño?

```{r, echo=TRUE, results='hide'}
regresion_bayesiana_poco_warmup <- brm(
  formula = salario ~ PTS,
  data = nba_salarios_estadisticas_partido,
  warmup = 100,
  cores = 6,
  seed = 1992
)
```
```{r}
summary(regresion_bayesiana_poco_warmup)
```
```{r}
plot(regresion_bayesiana_poco_warmup, ask = FALSE)
```

https://cran.r-project.org/web/packages/tidybayes/vignettes/tidy-brms.html

https://www.r-bloggers.com/2019/11/creating-and-using-a-simple-bayesian-linear-model-in-brms-and-r/

https://michael-franke.github.io/intro-data-analysis/extracting-posterior-samples.html

http://mjskay.github.io/tidybayes/articles/tidy-brms.html

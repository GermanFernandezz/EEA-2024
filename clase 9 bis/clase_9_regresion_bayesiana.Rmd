---
title: "Regresión Bayesiana"
author: "Juan Barriola, Azul Villanueva y Franco Mastelli"
date: "15 de Octubre de 2022"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
---

<style type="text/css">
div.main-container {
  max-width: 1600px;
  margin-left: auto;
  margin-right: auto;
}
</style>


```{r, message=FALSE}
# Carga de librerías
library(tidyverse)
library(tidymodels)
library(brms)
library(GGally)
```

En esta notebook desarrollaremos modelos de regresión clásica y bayesiana para explicar/predecir los salarios de los jugadores de la NBA para la temporada 2022-2023 en base a información de la temporada pasada.

# Datasets 

Trabajaremos con los datasets de salarios de la temporada 2022-2023 de la NBA y las estadísticas por partido de la temporada 2021-2022. La información se scrappeó de la página basketball-reference y la construcción estos datasets se encuentra en (link a la notebook).

Cargamos los datasets y realizamos un join entre ambos mediante el nombre del jugador

```{r}
# Salarios 2022-2023
salarios_nba = read_csv("../Fuentes/nba/salarios_nba_2023.csv")
# Estadísticas por partido 2021-2022
estadisticas_por_partido_nba = read_csv("../Fuentes/nba/estadisticas_por_partido_nba_2022.csv") %>%
  # Conservamos el primer tipo de posicion declarada
  mutate(Pos = str_remove(string = Pos, pattern = "\\-.*"))
# Realizamos un join entre ambas tablas mediante el nombre
nba_salarios_estadisticas_partido = salarios_nba %>% 
                            inner_join(y=estadisticas_por_partido_nba, on=jugador) %>% 
                            drop_na()

```
# Analisis exploratorios

Como se mencionó previamente, nuestro interés está en explicar la variable del salario anual. Usaremos pocas variables para mantener los modelos sencillos:

**Variable dependiente**

* salario: salario anual de la temporada 2022-23

**Variables independientes**

* PTS: puntos por partido en la temporada 2021-22
* Age: edad en años del jugador en la temporada 2021-22
* TRB: rebotes totales (ofensivos y defensivos) por partidoen la temporada 2021-22

Realizamos primero un correlagrama entre las 4 variables numéricas

```{r}
nba_salarios_estadisticas_partido %>% 
  select(Age, PTS, TRB, salario) %>% 
  ggpairs(upper = list(continuous = wrap("cor", size = 3, hjust=0.5)), progress=FALSE) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position = "bottom") + 
  theme_bw() +
  labs(title='Correlograma variables continuas')
```

Observamos:

* Todas las variables presentan asimetría positica. Se destaca la distribución del salario con una asimetrìa muy fuerte

* Las tres variables presentan una correlación positiva con el salario. Los puntos por partido presentan una correlación fuerte (0.798) mientras que los rebotes totales por partido y la edad presentan valores de correlación más moderados


```{r}
ggplot(data = nba_salarios_estadisticas_partido, aes(x=Pos, y=salario, fill=Pos)) +
  geom_boxplot() +
  theme_bw()
```


# Modelo lineal clásico

## Modelo simple

Realicemos un modelo de regresión simple para predecir el salario en función de los puntos por partido:

$Salario = \beta_0 + \beta_1 Puntos + \varepsilon$

Recordemos que el enfoque clásico postula parámetros fijos y desconocidos y un target aleatorio

$Y \sim N(\beta_0+\beta_1X, \sigma)$

Siendo $\beta_0, \beta_1, \sigma$ los parámetros fijos y desconocidos que debemos estimar.

```{r}
# Fiteamos el modelo
modelo_clasico_puntos = lm(data = nba_salarios_estadisticas_partido, formula = salario ~ PTS)
```

Observamos los valores de los coeficientes estimados junto con el p-valor del test de significatividad individual y los límites de los intervalos de confianza al 95%

```{r}
# Observamos los valores de los coeficientes estimados
tidy(modelo_clasico_puntos, conf.int = TRUE)
```
Observamos los valores de sigma y el p-valor del test de significatividad global

```{r}
# Observamos los valores de la evaluación global
glance(modelo_clasico_puntos)
```
## Modelo múltiple

```{r}
# Fiteamos el modelo
modelo_clasico_multiple = lm(data = nba_salarios_estadisticas_partido, formula = salario ~ PTS + Age + TRB)
```

Observamos los valores de los coeficientes estimados junto con el p-valor del test de significatividad individual y los límites de los intervalos de confianza al 95%

```{r}
# Observamos los valores de los coeficientes estimados
tidy(modelo_clasico_multiple, conf.int = TRUE)
```

Observamos los valores de sigma y el p-valor del test de significatividad global

```{r}
# Observamos los valores de la evaluación global
glance(modelo_clasico_multiple)
```
## Modelo categóricas

```{r}
# Fiteamos el modelo
modelo_clasico_categoricas = lm(data = nba_salarios_estadisticas_partido, formula = salario ~ PTS + Pos)
```

Observamos los valores de los coeficientes estimados junto con el p-valor del test de significatividad individual y los límites de los intervalos de confianza al 95%

```{r}
# Observamos los valores de los coeficientes estimados
tidy(modelo_clasico_categoricas, conf.int = TRUE)
```
Observamos los valores de sigma y el p-valor del test de significatividad global

```{r}
# Observamos los valores de la evaluación global
glance(modelo_clasico_categoricas)
```

# Modelos Bayesianos

Recordemos que el enfoque bayesiano postula parámetros aleatorios

Vamos a utilizar la implementación de modelos bayesianos de la librería **brms**

La función que vamos a utilizar es `brm()` la cual permite construir una gran variedad de modelos bayesianos. Algunos de sus parámetros más relevantes son: 

**Modelo**

* `formula`: la fórmula del modelo que queremos realizar

* `data`: dataset a utilizar

* `family`: distribución de la variable respuesta/target y función link. Por default se aplica la distribución gaussiana/normal

* `prior`: distribuciones prior de los parámetros

**Simulación**

* `init`: valores iniciales para el muestreo de los parámetros. Por default es random

* `chains`: cantidad de cadenas de Markov. Por default son 4

* `iter`: cantidad de iteraciones totales por cadena incluyendo warmup. Por default son 2000

* `warmup`: cantidad de iteraciones de warmup. Por default es iter/2

**Ejecución**

* `cores`: cantidad de núcleos a utilizar en la ejecución de las cadenas de manera paralelizada. Por default es 1.

* `seed`: semilla para reproducibilidad

## Modelo simple

Realicemos un primer modelo con la configuración default

```{r, echo=TRUE, results='hide'}
regresion_bayesiana_simple <- brm(
  formula = salario ~ PTS,
  data = nba_salarios_estadisticas_partido,
  cores = 6,
  seed = 1992
)
```
Observemos los resultados del modelo

```{r}
summary(regresion_bayesiana_simple)
```
```{r}
regresion_bayesiana_simple$fit
```

```{r}
plot(regresion_bayesiana_simple, ask = FALSE)
```

## Tidybayes

```{r}
library(tidybayes)
```

```{r}
get_variables(regresion_bayesiana_simple)
```


```{r}
regresion_bayesiana_simple %>%
  spread_draws(b_Intercept, b_PTS, sigma)
```

```{r}
regresion_bayesiana_simple %>%
  gather_draws(b_Intercept, b_PTS, sigma) %>% 
  mean_qi()
```



```{r}
regresion_bayesiana_simple %>%
  gather_draws(b_Intercept, b_PTS, sigma) %>% 
  summarise_draws()
```



```{r}
regresion_bayesiana_simple %>% 
  gather_draws(b_Intercept, b_PTS, sigma) %>% 
  ggplot(aes(x=.iteration, y=.value, color=factor(.chain))) +
  geom_line() +
  facet_wrap(facets = ~.variable, ncol=1,scales = 'free') +
  scale_color_discrete() +
  theme_bw()

```

## Modelo simple: Priors

### Priors adecuadas

### Priors inadecuadas

## Modelo multiple

Realicemos un primer modelo con la configuración default

```{r, echo=TRUE, results='hide'}
regresion_bayesiana_multiple <- brm(
  formula = salario ~ PTS + Age + TRB,
  data = nba_salarios_estadisticas_partido,
  cores = 6,
  seed = 1992
)
```

```{r}
summary(regresion_bayesiana_multiple)
```
## Modelo categóricas

# Experimentos

## Sin warm-up

¿Qué pasa con nuestro modelo si no realizamos warmup?

```{r, echo=TRUE, results='hide'}
regresion_bayesiana_no_warmup <- brm(
  formula = salario ~ PTS,
  data = nba_salarios_estadisticas_partido,
  warmup = 0,
  cores = 6,
  seed = 1992
)
```
```{r}
summary(regresion_bayesiana_no_warmup)
```
```{r}
plot(regresion_bayesiana_no_warmup, ask = FALSE)
```

## Poco warm-up

¿Qué pasa con nuestro modelo si realizamos un warmup muy pequeño?

```{r, echo=TRUE, results='hide'}
regresion_bayesiana_poco_warmup <- brm(
  formula = salario ~ PTS,
  data = nba_salarios_estadisticas_partido,
  warmup = 100,
  cores = 6,
  seed = 1992
)
```
```{r}
summary(regresion_bayesiana_poco_warmup)
```
```{r}
plot(regresion_bayesiana_poco_warmup, ask = FALSE)
```

https://cran.r-project.org/web/packages/tidybayes/vignettes/tidy-brms.html

https://www.r-bloggers.com/2019/11/creating-and-using-a-simple-bayesian-linear-model-in-brms-and-r/

https://michael-franke.github.io/intro-data-analysis/extracting-posterior-samples.html

http://mjskay.github.io/tidybayes/articles/tidy-brms.html

---
title: "Trabajo Práctico Nº1"
author: "J. Germán Fernández"
date: "19 de Octubre de 2024"
subtitle: "Enfoque Estadístico del Aprendizaje"
output:
  html_document:
    toc: yes
    code_folding: show
    toc_float: yes
    df_print: paged
    theme: united
    code_download: yes
  html_notebook:
    theme: spacelab
    toc: yes
    toc_float: yes
    df_print: paged
---

<style type="text/css">
div.main-container {
  max-width: 1600px;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r, echo=FALSE}
options(scipen = 8)
```

```{r, warning=F, message=F}
library(tidyverse)
library(tidymodels)
library(gridExtra)
library(GGally)
library(corrplot)
library(corrr)
library(gridExtra)
library(MASS)
library(kableExtra)
library(janitor)
```

# Introducción

El objetivo del presente trabajo es predecir mediante modelos lineales simples y múltiples el salario por hora de los trabajadores de la República Argentina y encontrar cual sería el mejor modelo que explique esa variabilidad.

Para lograr estos objetivos utilzaremos un muestreo de la Encuesta Permanente de Hogares del tercer trimestre del año 2023. La cual ya se encuentra particionado en Entrenamiento y Prueba.


```{r}
#Cargo los datos
datos <- read.csv("eph_train_2023.csv")
```


# Análisis Exploratorio de datos

En primer lugar se realiza una análisis explotarios de datos para comprender que datos tenemos y como se comportan.

La siguiente tabla muestra los tipos de variables y algunos datos de ellas.

```{r}
#Variables numericas----
#Estructura de los datos
datos %>% glimpse()
```

```{r}
#Quito años, trimesrte y fecha de nacimiento que no los voy a usar
#datos <- datos[-c(2,3,6)]
datos$aglomerado <- as.factor(datos$aglomerado)
datos$codigo_actividad <- as.factor(datos$codigo_actividad)
datos <- datos[-c(2,3,6)]
```

Se eliminan las variables año y trimestre ya que es la misma para todos los datos, y la variable fecha de nacimento ya que sería redundante y seguramente correlacione altamente con la edad de los individuos, además viendo los dos primero datos se percibe que no están bien ingresados.

En la siguiente table se ven los datos faltantes. Se observa que hay un bajo porcentaje de datos faltantes solo en asistencia_educacion, se decide eliminar ese único dato.
```{r}
tabla_exploratorios =  datos %>%
  gather(., 
         key = "variables", 
         value = "valores") %>% # agrupamos por las variables del set
  group_by(variables) %>% 
  summarise(valores_unicos = n_distinct(valores),
            porcentaje_faltantes = sum(is.na(valores))/nrow(datos)*100) %>% 
  arrange(desc(porcentaje_faltantes), valores_unicos) # ordenamos por porcentaje de faltantes y valores unicos
tabla_exploratorios
#Saco ese único NA
datos <- subset(datos, !is.na(asistencia_educacion))
```

## Variables categóricas

Los siguientes gráficos de barras muestras la distribución de algunas de las variables categóricas que podría llegar a tener en consideración para el diseño de los modelos de predicción ya que creemos que podrían tener influencia en el salario de los trabajadores.

```{r}
# Boxplots de variables categorias que puedo utilizar en modelos
g1 <- ggplot(datos, aes(x=region, fill=region))+
  geom_bar()+
  theme_bw()+
  theme(legend.position = "none",axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(size = 8),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())+
  ggtitle("Distribución de trabajadores por región")

g2 <- ggplot(datos, aes(x=nivel_ed, fill=nivel_ed))+
  geom_bar()+
  theme_bw()+
  theme(legend.position = "none",axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(size = 8),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())+
  ggtitle("Distribución de trabajadores por nivel educativo")

g3 <- ggplot(datos, aes(x=tipo_establecimiento, fill=tipo_establecimiento))+
  geom_bar()+
  theme_bw()+
  theme(legend.position = "none",axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(size = 8),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())+
  ggtitle("Distribución de trabajadores por tipo de establecimiento")

g4 <- ggplot(datos, aes(x=categoria_ocupacion, fill=categoria_ocupacion))+
  geom_bar()+
  theme_bw()+
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(size = 8),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())+
  ggtitle("Distribución de trabajadores por puesto laboral")+
  scale_x_discrete(labels = c("Trabajador sin remuneracion" = "Sin salario"))
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```

## Variables numéricas

En el siguiente gráfico se puede observar los gráficos de dispersión de todas las variables numéricas y sus correlaciones.

Las variables experiencia potencial y edad están altamente correlacionadas positivamente, salario y salario por hora también pero en menor medidad.

Entre Experiencia potencial y educación se observa una ligera correlación negativa, mientras que entre salario y salario hora contra educación la correlación es ligamente positiva.

En el resto de las variables no ser pericibe correlación alguna.

```{r}
#Grafico de correlaciones
grafico1 <- datos %>%
  select_if(is.numeric) %>%
  ggpairs()

grafico1
```

En el siguiente gráfico de correlaciones se pueden apreciar mejor las relaciones entre variables previamente descriptas.

```{r}
m_cor <- datos %>%
  select_if(is.numeric) %>%
  cor()
corrplot(m_cor,
         method="circle",
         type = "upper",
         addCoef.col = "black",
         diag= FALSE) 
```

```{r}
#datos %>% 
#  select_if(is.numeric) %>% # selecciona las variables numericas 
#  correlate(method = 'spearman') %>% # convierte la matriz de corr en dataframe
#  shave() %>% # solo muestra información debajo de la diagonal principal
#  fashion(decimals = 3) # acomoda los datos en forma tidy (por ej. redondeo de decimales)
```

El siguiente gráfico muestra las correlaciones pero haciendo una apertura por sexo.

Se observa que según el sexo las correlaciones se mantienen. Sin embargo, se observa que los valores del coeficiente de correlacion de Pearson de todas las variables contra Salario por hora son ligaramente mayores en hombre, salvo en el caso de educación donde el coeficiente de correlacion es favorable para las muejeres.

```{r}
grafico2 <- datos %>% 
  select_if(is.numeric) %>% 
  mutate(sexo = datos$sexo) %>%
  ggpairs(., mapping = aes(colour = sexo), title = "Matriz de correlaciones",
          upper = list(continuous = wrap("cor", size = 3, hjust=0.5)), legend = 25) + 
  theme_bw() +
  theme(axis.text.x = element_text(angle=45, vjust=0.5), legend.position = "bottom")

grafico2 #no veo inconsistencias severas en este gráfico
```

# Modelos

## Primero modelo lineal

El primer modelo lineal consiste en explicar el Salario por Hora según la variable Eperiencia Potencial.

Primero graficamos las dos variables.

```{r}
#2)Modelos lineales experiencia----
ggplot(datos, aes(x=experiencia_potencial, y= salario_horario))+
  geom_point()+
  labs(title = "Experiencia Potencial vs Salario por Hora", x= "Experiencia Potencial", y="Salario por hora")+
  theme_bw()
```

Parecería observarse un aumento del salario a medida que aumenta la Experiencia Potencial pero llegada una edad entre 35 y 40 años de Experiencia Potencial el salario por hora parece empezar a disminuir.

Veamos como explica esto un modelo lineal simple del siguiente estilo:

E(SalarioHorario) = β0 + β1*ExperienciaPotencial

### Evaluacion del primer modelo lineal simple

Con este modelo queremos inferir β1 y verificar si la relacion entre la variable independiente y la variable a explicar es estadísticamente significativa mediantes el siguiente test de hiótesis:

H0: β1=0
 
H1: β1≠0

```{r}
#No parece una relación muy lineal pero miremos el modelo: salario_horario vs exp_pot
modelo_simple_salhor_hr = lm(formula = salario_horario ~ experiencia_potencial, data = datos)
# Observamos que devuelve el modelo
summary(modelo_simple_salhor_hr)
```

Este modelo nos dice que el salario por hora aumenta $2,37 por cada año adicional de Experiencia Potencial y que β1 es distinto de cero, ya que el p-valor < 0,05, por lo tanto esa variable es significativa para explicar la variación del Salario por Hora.

Sin embargo, este modelo explica solo un 0,1% de la variabilidad.

### Diagnóstico del primer modelo lineal simple

Se realiza el diagnóstico para verificar si los errores tienenn una distrbución normal centrada en cero y de varianza constante.

```{r}
datos_augmentados <- augment(modelo_simple_salhor_hr)
g1 = ggplot(datos_augmentados, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(datos_augmentados, aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(datos_augmentados, aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(datos_augmentados, aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```
Residuos vs valores predichos: se observa claramente que los residuos no están centrados en cero.

Normal Q-Q plot: claramente los errores no son normales ya que en ambos extremos se desvía considerablemente de la recta normal.

Residuos vs leverage: tomando como referencia que los datos con leverage mayor a 0,5 serían los potencialmente influyentes, podemos decir que ninguno cumple con esta función.

## Segundo Modelo Lineal

Ajustamos otro modelo un poco mas complejo:

E(SalarioHorario) = β0 + β1*Experiencia Potencial + β2*$Experiencia Potencial^2$

Este modelo puede que sea mas explicativo de la disminución que se observa gráficamente del Salario por Hora a partir de una determinada Experiencia Potencial.

### Evaluacion del segundo modelo lineal

```{r}
#Modelo salario_horario vs exp_pot + exp_pot^2
modelo_multiple_salhr_hr = lm(formula = salario_horario ~ experiencia_potencial + I(experiencia_potencial^2), data = datos)
# Observamos que devuelve el modelo
summary(modelo_multiple_salhr_hr)

```

En este modelo vamos que el p-valor de ambos coeficientes es menor a 0,05, por lo tanto ambos son significativos para explicar el Salario por Hora, pero también vemos que el coeficente de $ExperienciaPotencial^2$ tiende a dismnuir el salario a medida que aumenta la Experiencia Potencial.

Este modelo también explica un poco mejor la variabilidad, explicando un 1,2%, pero sigue siendo bastante bajo.

Veamos este comportamiento graficando las curvas de ambos modelos, donde la curva roja es el modelo mas simple y la curva el mas complejo.


```{r}
# Graficamos el dataset y los modelos
datos %>% ggplot(., aes(x = experiencia_potencial, y = salario_horario)) + 
  geom_point(color="grey") + #capa de los datos
  theme_bw() +
  geom_smooth(method = "lm", formula = y ~ x, color="forestgreen", se = FALSE) + # capa del modelo
  geom_smooth(method = "lm", formula = y ~ x + I(x^2), color = "red", se = FALSE) +  # Ajuste del modelo
  
  #scale_x_continuous(limits = c(0,65)) +
  #scale_y_continuous(limits = c(0,550000)) +
  labs(title="Modelo Lineal Simple: Salario Horario", x="Experiencia Potencial", y="Salario Hora") 
```
En este gráfico se puede observar como la curva del modelo mas complejo tiene un máximo a los 30 años aproximados de experiencia potencial y comienza a declinar.

Veamos este comportamiento tamando como varía un año mas de experiencia laboral si se tienen 6 años de experiencia potencial o 35 años de experiencia potencial.

```{r}
df_predicciones <- data.frame(experiencia_potencial=c(6,7,35,36))
df_predicciones$predicciones <- predict(modelo_multiple_salhr_hr,df_predicciones)

experiencia_6 <- df_predicciones$predicciones[2] - df_predicciones$predicciones[1]
experiencia_35 <- df_predicciones$predicciones[4] - df_predicciones$predicciones[3]
```


```{r}
cat("Variación del salario con un año de mas de experiencia si se tienen 6 años de Experiencia Potencial", experiencia_6)
```
```{r}
cat("Variación del salario con un año de mas de experiencia si se tienen 35 años de Experiencia Potencial", experiencia_35)
```

### Diagnóstico del primer modelo lineal simple

Se realiza el diagnóstico para verificar si los errores tienenn una distrbución normal centrada en cero y de varianza constante.

```{r}
datos_augmentados <- augment(modelo_multiple_salhr_hr)
g1 = ggplot(datos_augmentados, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(datos_augmentados, aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(datos_augmentados, aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(datos_augmentados, aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```

Residuos vs valores predichos: se observa claramente que los residuos no están centrados en cero y además al presentar una curvatura evidencia una estructura en los datos.

Normal Q-Q plot: claramente los errores no son normales ya que en ambos extremos se desvía considerablemente de la recta normal.

Residuos vs leverage: tomando como referencia que los datos con leverage mayor a 0,5 serían los potencialmente influyentes, podemos decir que ninguno cumple con esta función.

## Modelo lineal múltiple de Mincer

Veamos si podemos seguir mejorando la explicación y predicción de la variable Salario por hora utilizando un modelo mas complejo como la ecuación de Mincer:

E(SalarioHorario) = β0 + β1AñosEducacion + β2ExperienciaP otencial + β3ExperienciaP otencial2 + β4Sexo + β5Sexo · AñosEducacion

### Evaluacion del modelo de Mincer

```{r}
#3) Modelo lineal multiple----
datos$sexo <- factor(datos$sexo)

modelo_mincer1 <- lm(formula = salario_horario ~ educacion + 
                       experiencia_potencial + 
                       I(experiencia_potencial^2) +
                       sexo +
                       sexo*educacion,
                     data=datos)
summary(modelo_mincer1, conf.int = T)
```

Sobre la significancia indivudual de cada coeficiente podemos decir que todos significativos, salvo cuando condicionamos la variable educación a sexo, donde no es significativa para explicar el Salario por hora.

El test F de significatividad global es menor a 0,05, por lo tanto podemos asegurar que por lo menos una de las variables regresoreas sirve para predecir el Salario por hora.

En este caso tenemos una variable categórica, el Sexo, por lo tanto tenemos que revisar los valores del test F de significatividad conjunta de esta variable realizando un test ANOVA del modelo.

```{r}
tidy(anova(modelo_mincer1))
```

El p-valor de la variable Sexo es menor a 0,05, por lo tanto es significativa para explicar la evolución del Salario por hora.

El coeficiente de la variable Sexo nos indica que los varones en igualdad de condiciones de Experiencia Potencial y Educación reciben una Salario por hora $225,2 mayor que las mujeres.

El valor de $R^2$ de este modelo nos indica que podemos explicar un 16,7% de la variabilidad, mejorando notablemente con respecto a los modelos anteriores.

### Diagnóstico del modelo de Mincer

```{r}
datos_augmentados <- augment(modelo_mincer1)

g1 = ggplot(datos_augmentados, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(datos_augmentados, aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(datos_augmentados, aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(datos_augmentados, aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```

Nuevamente vemos que no se cumplen los supuestos distribucion normal centrada en cero y mismva varianza de los errores.

## Modelos múltiple de Mincer "enriquecido"

Veamos como se comporta este modelo si aplicamos una transformación logarítmica a la variable a predecir:

[ln(SalarioHorario)] = β0 + β1AñosEducacion + β2ExperienciaP otencial + β3ExperienciaP otencial2 + β4Sexo + β5Sexo · AñosEducacion


### Evaluacion del modelo de Mincer "enriquecido"
```{r}
modelo_mincer2 <- lm(formula = log(salario_horario) ~ educacion + 
                       experiencia_potencial + 
                       I(experiencia_potencial^2) +
                       sexo +
                       sexo*educacion,
                     data=datos)
summary(modelo_mincer2)
```

Sobre la significancia indivudual de cada coeficiente podemos decir que todos son significativos.

El test F de significatividad global es menor a 0,05, por lo tanto podemos asegurar que por lo menos una de las variables regresoreas sirve para predecir el Salario por hora.

En este caso tenemos nuevamente una variable categórica, el Sexo, por lo tanto tenemos que revisar los valores del test F de significatividad conjunta de esta variable realizando un test ANOVA del modelo.

Cabe aclarar que la interpretación de como varía el salario por hora en esta modelo es diferente a los anteriores ya que tenemos una relación de semielasticidad, siendo de la siguiente manera:
Educación: el salario por hora aumenta 9.6% si se aumenta un año en la educación del trabajador.
Sexo: el salario por hora es un 28% mayor si el trabajador es varón.


```{r}
tidy(anova(modelo_mincer2))
```

Nuevamente, la variable sexo es significativa para explicar la variación del Salario por Hora de los trabajadores.

En este caso, el valor de $R^2$ del modelo es con respecto a la variable transformada, por lo tanto tenemos que predecir todos los datos utilizados en el modelo y trasformarlos exponencialmente para obtener el valor real del salario por hora.

Finalemente se calcula el valor de $R^2$ "manualmente".

```{r}
# Predicciones en el logaritmo del salario
pred_log_salario <- predict(modelo_mincer2)

# Convertir las predicciones al salario horario original (inverso del logaritmo)
pred_salario <- exp(pred_log_salario)

# Salario horario observado (original)
salario_observado <- datos$salario_horario

# Calcular el R^2 corregido
r2_salario <- 1 - sum((salario_observado - pred_salario)^2) / sum((salario_observado - mean(salario_observado))^2)

cat("$R^2$ = ", r2_salario)
```
En este caso, el modelo explica un 12,15% de la variabilidad total del Salario por hora de los trabajadores.

Este resultado no es mejor que el modelo anterior, pero ahora veremos que es mas confiable ya que los datos se aproximan mas a los supuestos que debe cumplir.

### Diagnóstico del modelo de Mincer "enriquecido"

```{r}
#Uso augment para calcular las variables necesarios para hacer los gráficos con ggplot
datos_augmentados <- augment(modelo_mincer2)

g1 = ggplot(datos_augmentados, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(datos_augmentados, aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(datos_augmentados, aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(datos_augmentados, aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```

Residuos vs valores predichos: en este caso se observa que los valores están centrados en cero, cunmpliendo uno de los supuestos.

Normal Q-Q plot: los valores siguen desviándose de la normal en los extremos, pero mejorar notablemente con respecto a los modelos anteriores.

Residuos vs leverage: siguen siendo todos menores a 0,5, por lo tanto ningún datos tiene una influencia mayor en el modelo.

Por lo tanto, este modelo es mas confiable que el del Mincer "sin enriquecer".

## Primer Modelo Propio

El objetivo de este modelo es lograr ver la variación de salario por hora según la región en la cual habita el trabajador.

```{r}
#5)Modelos propios y evaluacion----

#Modelo propio 1----
modelo_propio1 <- lm(formula = log(salario_horario) ~ educacion +
                                     region +
                                     experiencia_potencial+educacion*region,
                                   data = datos)
summary(modelo_propio1)
```

```{r}
tidy(anova(modelo_propio1))
```


```{r}
#Uso augment para calcular las variables necesarios para hacer los gráficos con ggplot
datos_augmentados <- augment(modelo_propio1)

g1 = ggplot(datos_augmentados, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(datos_augmentados, aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(datos_augmentados, aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(datos_augmentados, aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```

```{r}
# Predicciones en el logaritmo del salario
pred_log_salario <- predict(modelo_propio1)

# Convertir las predicciones al salario horario original (inverso del logaritmo)
pred_salario <- exp(pred_log_salario)

# Salario horario observado (original)
salario_observado <- datos$salario_horario

# Calcular el R^2 corregido
r2_salario <- 1 - sum((salario_observado - pred_salario)^2) / sum((salario_observado - mean(salario_observado))^2)

print(r2_salario) 
```

```{r}
#Modelo propio 2----
modelo_propio2 <- lm(formula = log(salario_horario) ~ edad +  categoria_ocupacion + sexo,
                     data = datos)
summary(modelo_propio2)
```

```{r}
tidy(anova(modelo_propio2))
```


```{r}
#Uso augment para calcular las variables necesarios para hacer los gráficos con ggplot
datos_augmentados <- augment(modelo_propio2)

g1 = ggplot(datos_augmentados, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(datos_augmentados, aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(datos_augmentados, aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(datos_augmentados, aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```

```{r}
# Predicciones en el logaritmo del salario
pred_log_salario <- predict(modelo_propio1)

# Convertir las predicciones al salario horario original (inverso del logaritmo)
pred_salario <- exp(pred_log_salario)

# Salario horario observado (original)
salario_observado <- datos$salario_horario

# Calcular el R^2 corregido
r2_salario <- 1 - sum((salario_observado - pred_salario)^2) / sum((salario_observado - mean(salario_observado))^2)

print(r2_salario)
```

```{r}
#testeo----
test <- read.csv("eph_test_2023.csv")

pred_modelo_propio1 <- augment(modelo_propio1, newdata = test)
pred_modelo_propio1$exp_fitted <- exp(pred_modelo_propio1$.fitted)

pred_modelo_mincer1 <- augment(modelo_mincer1, newdata = test)

pred_modelo_mincer2 <- augment(modelo_mincer2, newdata = test)
pred_modelo_mincer2$exp_fitted <- exp(pred_modelo_mincer2$.fitted)

pred_modelo_propio2 <- augment(modelo_propio2, newdata = test)
pred_modelo_propio2$exp_fitted <- exp(pred_modelo_propio2$.fitted)
library(janitor)
# Calcular las métricas
metrics <- tibble(
  Model = c("Modelo Propio 1", "Modelo Mincer 1", "Modelo Mincer 2", "Modelo Propio 2"),
  RMSE = c(
    rmse(data = pred_modelo_propio1, truth = salario_horario, estimate = exp_fitted)$.estimate,
    rmse(data = pred_modelo_mincer1, truth = salario_horario, estimate = .fitted)$.estimate,
    rmse(data = pred_modelo_mincer2, truth = salario_horario, estimate = exp_fitted)$.estimate,
    rmse(data = pred_modelo_propio2, truth = salario_horario, estimate = exp_fitted)$.estimate
  ),
  MAE = c(
    mae(data = pred_modelo_propio1, truth = salario_horario, estimate = exp_fitted)$.estimate,
    mae(data = pred_modelo_mincer1, truth = salario_horario, estimate = .fitted)$.estimate,
    mae(data = pred_modelo_mincer2, truth = salario_horario, estimate = exp_fitted)$.estimate,
    mae(data = pred_modelo_propio2, truth = salario_horario, estimate = exp_fitted)$.estimate
  )
)

# Opcional: Limpiar los nombres de las columnas
metrics <- clean_names(metrics)

# Mostrar la tabla
print(metrics)
```
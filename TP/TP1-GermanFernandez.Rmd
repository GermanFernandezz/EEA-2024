---
title: "Trabajo Práctico Nº1"
author: "J. Germán Fernández"
date: "19 de Octubre de 2024"
subtitle: "Enfoque Estadístico del Aprendizaje"
output:
  html_document:
    toc: yes
    code_folding: show
    toc_float: yes
    df_print: paged
    theme: united
    code_download: yes
  html_notebook:
    theme: spacelab
    toc: yes
    toc_float: yes
    df_print: paged
---

<style type="text/css">
div.main-container {
  max-width: 1600px;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r, echo=FALSE}
options(scipen = 8)
```

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(gridExtra)
library(GGally)
library(corrplot)
library(corrr)
library(gridExtra)
library(MASS)
library(kableExtra)
library(janitor)
library(broom)
```

# Introducción

El objetivo del presente trabajo es predecir mediante modelos lineales simples y múltiples el salario por hora de los trabajadores de la República Argentina y encontrar cual sería el mejor modelo que explique esa variabilidad.

Para lograr estos objetivos utilzaremos un muestreo de la Encuesta Permanente de Hogares del tercer trimestre del año 2023. La cual ya se encuentra particionado en Entrenamiento y Prueba.


```{r}
#Cargo los datos
datos <- read.csv("eph_train_2023.csv")
```


# Análisis Exploratorio de datos

En primer lugar se realiza una análisis explotarios de datos para comprender que datos tenemos y como se comportan.

La siguiente tabla muestra los tipos de variables y algunos datos de ellas.

```{r}
#Variables numericas----
#Estructura de los datos
datos %>% glimpse()
```

```{r}
#Quito años, trimesrte y fecha de nacimiento que no los voy a usar
#datos <- datos[-c(2,3,6)]
datos$aglomerado <- as.factor(datos$aglomerado)
datos$codigo_actividad <- as.factor(datos$codigo_actividad)
datos <- datos[-c(2,3,6)]
```

Se eliminan las variables año y trimestre ya que es la misma para todos los datos, y la variable fecha de nacimento ya que sería redundante y seguramente correlacione altamente con la edad de los individuos, además viendo los dos primero datos se percibe que no están bien ingresados.

En la siguiente table se ven los datos faltantes. Se observa que hay un bajo porcentaje de datos faltantes solo en asistencia_educacion, se decide eliminar ese único dato.
```{r}
tabla_exploratorios =  datos %>%
  gather(., 
         key = "variables", 
         value = "valores") %>% # agrupamos por las variables del set
  group_by(variables) %>% 
  summarise(valores_unicos = n_distinct(valores),
            porcentaje_faltantes = sum(is.na(valores))/nrow(datos)*100) %>% 
  arrange(desc(porcentaje_faltantes), valores_unicos) # ordenamos por porcentaje de faltantes y valores unicos
tabla_exploratorios
#Saco ese único NA
datos <- subset(datos, !is.na(asistencia_educacion))
```

## Variables categóricas

Los siguientes gráficos de barras muestras la distribución de algunas de las variables categóricas que podría llegar a tener en consideración para el diseño de los modelos de predicción ya que creemos que podrían tener influencia en el salario de los trabajadores.

```{r}
# Boxplots de variables categorias que puedo utilizar en modelos
g1 <- ggplot(datos, aes(x=region, fill=region))+
  geom_bar()+
  theme_bw()+
  theme(legend.position = "none",axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(size = 8),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())+
  ggtitle("Distribución de trabajadores por región")

g2 <- ggplot(datos, aes(x=nivel_ed, fill=nivel_ed))+
  geom_bar()+
  theme_bw()+
  theme(legend.position = "none",axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(size = 8),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())+
  ggtitle("Distribución de trabajadores por nivel educativo")

g3 <- ggplot(datos, aes(x=tipo_establecimiento, fill=tipo_establecimiento))+
  geom_bar()+
  theme_bw()+
  theme(legend.position = "none",axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(size = 8),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())+
  ggtitle("Distribución de trabajadores por tipo de establecimiento")

g4 <- ggplot(datos, aes(x=categoria_ocupacion, fill=categoria_ocupacion))+
  geom_bar()+
  theme_bw()+
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(size = 8),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())+
  ggtitle("Distribución de trabajadores por puesto laboral")+
  scale_x_discrete(labels = c("Trabajador sin remuneracion" = "Sin salario"))
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```

## Variables numéricas

En el siguiente gráfico se puede observar los gráficos de dispersión de todas las variables numéricas y sus correlaciones.

Las variables experiencia potencial y edad están altamente correlacionadas positivamente, salario y salario por hora también pero en menor medidad.

Entre Experiencia potencial y educación se observa una ligera correlación negativa, mientras que entre salario y salario hora contra educación la correlación es ligamente positiva.

En el resto de las variables no ser pericibe correlación alguna.

```{r}
#Grafico de correlaciones
grafico1 <- datos %>%
  select_if(is.numeric) %>%
  ggpairs()

grafico1
```

En el siguiente gráfico de correlaciones se pueden apreciar mejor las relaciones entre variables previamente descriptas.

```{r}
m_cor <- datos %>%
  select_if(is.numeric) %>%
  cor()
corrplot(m_cor,
         method="circle",
         type = "upper",
         addCoef.col = "black",
         diag= FALSE) 
```

```{r}
#datos %>% 
#  select_if(is.numeric) %>% # selecciona las variables numericas 
#  correlate(method = 'spearman') %>% # convierte la matriz de corr en dataframe
#  shave() %>% # solo muestra información debajo de la diagonal principal
#  fashion(decimals = 3) # acomoda los datos en forma tidy (por ej. redondeo de decimales)
```

El siguiente gráfico muestra las correlaciones pero haciendo una apertura por sexo.

Se observa que según el sexo las correlaciones se mantienen. Sin embargo, se observa que los valores del coeficiente de correlacion de Pearson de todas las variables contra Salario por hora son ligaramente mayores en hombre, salvo en el caso de educación donde el coeficiente de correlacion es favorable para las muejeres.

```{r}
grafico2 <- datos %>% 
  select_if(is.numeric) %>% 
  mutate(sexo = datos$sexo) %>%
  ggpairs(., mapping = aes(colour = sexo), title = "Matriz de correlaciones",
          upper = list(continuous = wrap("cor", size = 3, hjust=0.5)), legend = 25) + 
  theme_bw() +
  theme(axis.text.x = element_text(angle=45, vjust=0.5), legend.position = "bottom")

grafico2 #no veo inconsistencias severas en este gráfico
```

# Modelos

## Primero modelo lineal

El primer modelo lineal consiste en explicar el Salario por Hora según la variable Experiencia Potencial.

Primero graficamos las dos variables.

```{r}
#2)Modelos lineales experiencia----
ggplot(datos, aes(x=experiencia_potencial, y= salario_horario))+
  geom_point()+
  labs(title = "Experiencia Potencial vs Salario por Hora", x= "Experiencia Potencial", y="Salario por hora")+
  theme_bw()
```

Parecería observarse un aumento del salario a medida que aumenta la Experiencia Potencial pero llegada una edad entre 35 y 40 años de Experiencia Potencial el salario por hora parece empezar a disminuir.

Veamos como explica esto un modelo lineal simple del siguiente estilo:

E(SalarioHorario) = β0 + β1*ExperienciaPotencial

### Evaluacion del primer modelo lineal simple

Con este modelo queremos inferir β1 y verificar si la relacion entre la variable independiente y la variable a explicar es estadísticamente significativa mediante el siguiente test de hipótesis:

H0: β1=0
 
H1: β1≠0

```{r}
#No parece una relación muy lineal pero miremos el modelo: salario_horario vs exp_pot
modelo_simple_salhor_hr = lm(formula = salario_horario ~ experiencia_potencial, data = datos)
# Observamos que devuelve el modelo
summary(modelo_simple_salhor_hr)
```

Este modelo nos dice que el salario por hora aumenta $2,37 por cada año adicional de Experiencia Potencial y que β1 es distinto de cero, ya que el p-valor < 0,05, por lo tanto esa variable es significativa para explicar la variación del Salario por Hora.

Sin embargo, este modelo explica solo un 0,1% de la variabilidad.

### Diagnóstico del primer modelo lineal simple

Se realiza el diagnóstico para verificar si los errores tienen una distrbución normal centrada en cero y de varianza constante.

```{r}
datos_augmentados <- augment(modelo_simple_salhor_hr)
g1 = ggplot(datos_augmentados, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(datos_augmentados, aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(datos_augmentados, aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(datos_augmentados, aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```
Residuos vs valores predichos: se observa claramente que los residuos no están centrados en cero.

Normal Q-Q plot: claramente los errores no son normales ya que en ambos extremos se desvía considerablemente de la recta normal.

Residuos vs leverage: tomando como referencia que los datos con leverage mayor a 0,5 serían los potencialmente influyentes, podemos decir que ninguno cumple con esta función.

## Segundo Modelo Lineal

Ajustamos otro modelo un poco mas complejo:

E(SalarioHorario) = β0 + β1*Experiencia Potencial + β2*$Experiencia Potencial^2$

Este modelo puede que sea mas explicativo de la disminución que se observa gráficamente del Salario por Hora a partir de una determinada Experiencia Potencial.

### Evaluacion del segundo modelo lineal

```{r}
#Modelo salario_horario vs exp_pot + exp_pot^2
modelo_multiple_salhr_hr = lm(formula = salario_horario ~ experiencia_potencial + I(experiencia_potencial^2), data = datos)
# Observamos que devuelve el modelo
summary(modelo_multiple_salhr_hr)

```

En este modelo vamos que el p-valor de ambos coeficientes es menor a 0,05, por lo tanto ambos son significativos para explicar el Salario por Hora, pero también vemos que el coeficente de $ExperienciaPotencial^2$ tiende a dismnuir el salario a medida que aumenta la Experiencia Potencial.

Este modelo también explica un poco mejor la variabilidad, explicando un 1,2%, pero sigue siendo bastante bajo.

Veamos este comportamiento graficando las curvas de ambos modelos, donde la curva verde es el modelo mas simple y la roja el mas complejo.


```{r}
# Graficamos el dataset y los modelos
datos %>% ggplot(., aes(x = experiencia_potencial, y = salario_horario)) + 
  geom_point(color="grey") + #capa de los datos
  theme_bw() +
  geom_smooth(method = "lm", formula = y ~ x, color="forestgreen", se = FALSE) + # capa del modelo
  geom_smooth(method = "lm", formula = y ~ x + I(x^2), color = "red", se = FALSE) +  # Ajuste del modelo
  
  #scale_x_continuous(limits = c(0,65)) +
  #scale_y_continuous(limits = c(0,550000)) +
  labs(title="Modelo Lineal Simple: Salario Horario", x="Experiencia Potencial", y="Salario Hora") 
```
En este gráfico se puede observar como la curva del modelo mas complejo tiene un máximo a los 30 años aproximados de experiencia potencial y comienza a declinar.

Veamos este comportamiento tomando como varía un año mas de experiencia laboral si se tienen 6 años de experiencia potencial o 35 años de experiencia potencial.

```{r}
df_predicciones <- data.frame(experiencia_potencial=c(6,7,35,36))
df_predicciones$predicciones <- predict(modelo_multiple_salhr_hr,df_predicciones)

experiencia_6 <- df_predicciones$predicciones[2] - df_predicciones$predicciones[1]
experiencia_35 <- df_predicciones$predicciones[4] - df_predicciones$predicciones[3]
```


```{r}
cat("Variación del salario con un año de mas de experiencia si se tienen 6 años de Experiencia Potencial", experiencia_6)
```
```{r}
cat("Variación del salario con un año de mas de experiencia si se tienen 35 años de Experiencia Potencial", experiencia_35)
```

### Diagnóstico del segundo modelo lineal

Se realiza el diagnóstico para verificar si los errores tienen una distrbución normal centrada en cero y  varianza constante.

```{r}
datos_augmentados <- augment(modelo_multiple_salhr_hr)
g1 = ggplot(datos_augmentados, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(datos_augmentados, aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(datos_augmentados, aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(datos_augmentados, aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```

Residuos vs valores predichos: se observa claramente que los residuos no están centrados en cero y además al presentar una curvatura evidencia una estructura en los datos.

Normal Q-Q plot: claramente los errores no son normales ya que en ambos extremos se desvía considerablemente de la recta normal.

Residuos vs leverage: tomando como referencia que los datos con leverage mayor a 0,5 serían los potencialmente influyentes, podemos decir que ninguno cumple con esta función.

## Modelo lineal múltiple de Mincer

Veamos si podemos seguir mejorando la explicación y predicción de la variable Salario por hora utilizando un modelo mas complejo como la ecuación de Mincer:

E(SalarioHorario) = β0 + β1AñosEducacion + β2ExperienciaP otencial + β3ExperienciaP otencial2 + β4Sexo + β5Sexo · AñosEducacion

### Evaluacion del modelo de Mincer

```{r}
#3) Modelo lineal multiple----
datos$sexo <- factor(datos$sexo)

modelo_mincer1 <- lm(formula = salario_horario ~ educacion + 
                       experiencia_potencial + 
                       I(experiencia_potencial^2) +
                       sexo +
                       sexo*educacion,
                     data=datos)
summary(modelo_mincer1, conf.int = T)
```

Sobre la significancia indivudual de cada coeficiente podemos decir que todos son significativos, salvo cuando condicionamos la variable educación a sexo, donde no es significativa para explicar el Salario por hora.

El test F de significatividad global es menor a 0,05, por lo tanto podemos asegurar que por lo menos una de las variables regresoreas sirve para predecir el Salario por hora.

En este caso tenemos una variable categórica, el Sexo, por lo tanto tenemos que revisar los valores del test F de significatividad conjunta de esta variable realizando un test ANOVA del modelo.

```{r}
tidy(anova(modelo_mincer1))
```

El p-valor de la variable Sexo es menor a 0,05, por lo tanto es significativa para explicar la evolución del Salario por hora.

El coeficiente de la variable Sexo nos indica que los varones sin Experiencia Potencial y sin Educación reciben una Salario por hora $225,2 mayor que las mujeres. En resumen, se podría decir que los varones tienen sueldos mayores cuando consiguen si primer trabajo comparado con el primer trabajo de las mujeres.

Sin embargo, el coeficiente de educación:sexoVaron indica que a medida que los varones adquieren mayores niveles de educación el salario crece un 6,42$ menos que el de las mujeres.

El valor de $R^2$ de este modelo nos indica que podemos explicar un 16,7% de la variabilidad, mejorando notablemente con respecto a los modelos anteriores. En este caso sería mas acertado verificar con el $R^2$ ajustado, donde también se observa una mejora notable en este modelo comparado con los anteriores.

### Diagnóstico del modelo de Mincer

```{r}
datos_augmentados <- augment(modelo_mincer1)

g1 = ggplot(datos_augmentados, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(datos_augmentados, aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(datos_augmentados, aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(datos_augmentados, aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```

Nuevamente vemos que no se cumplen los supuestos distribucion normal centrada en cero y misma varianza de los errores.

## Modelos múltiple de Mincer "enriquecido"

Veamos como se comporta este modelo si aplicamos una transformación logarítmica a la variable a predecir:

[ln(SalarioHorario)] = β0 + β1AñosEducacion + β2ExperienciaP otencial + β3ExperienciaP otencial2 + β4Sexo + β5Sexo · AñosEducacion


### Evaluacion del modelo de Mincer "enriquecido"
```{r}
modelo_mincer2 <- lm(formula = log(salario_horario) ~ educacion + 
                       experiencia_potencial + 
                       I(experiencia_potencial^2) +
                       sexo +
                       sexo*educacion,
                     data=datos)
summary(modelo_mincer2)
```

Sobre la significancia indivudual de cada coeficiente podemos decir que todos son significativos.

El test F de significatividad global es menor a 0,05, por lo tanto podemos asegurar que por lo menos una de las variables regresoras sirve para predecir el Salario por hora.

En este caso tenemos nuevamente una variable categórica, el Sexo, por lo tanto tenemos que revisar los valores del test F de significatividad conjunta de esta variable realizando un test ANOVA del modelo.

Cabe aclarar que la interpretación de como varía el salario por hora en esta modelo es diferente a los anteriores ya que tenemos una relación de semielasticidad, siendo de la siguiente manera:
Educación: el salario por hora aumenta 9.6% si se aumenta un año en la educación del trabajador.
Experiencia_Potencial: el salario por ahora aumenta 2,39% si se aumenta un año la experiencia potencial
Sexo: el salario por hora es un 28% mayor si el trabajador es varón.
educación:sexoVarón: este coeficiente indica que el salario de los varones por cada año adicional de educación aumenta un 1,15% menos que el de las mujeres.


```{r}
tidy(anova(modelo_mincer2))
```

Nuevamente, la variable sexo es significativa para explicar la variación del Salario por Hora de los trabajadores.

En este caso, el valor de $R^2$ del modelo es con respecto a la variable transformada, por lo tanto tenemos que predecir todos los datos utilizados en el modelo y trasformarlos exponencialmente para obtener el valor real del salario por hora.

Finalmente, se calcula el valor de $R^2$ "manualmente".

```{r}
# para ejecutar el anti-log usamos función exponencial
eval1 <- broom::augment(modelo_mincer2, datos)
eval1 = eval1 %>%  mutate(fitted_antilog = exp(.fitted))
# calculamos RMSE y R2 para las variables originales y no log(price) para que sea comparable con los demás modelos
metricas1 = metrics(data = eval1, truth = salario_horario, estimate = fitted_antilog) %>% mutate(.estimate = round(.estimate, 4))
rcuadrado <- metricas1$.estimate[2]
cat("R-cuadrado = ", rcuadrado)
```

En este caso, el modelo explica un 17,9% de la variabilidad total del Salario por hora de los trabajadores.

Este resultado es mejor que el modelo anterior, y además veremos que es mas confiable ya que los datos se aproximan mas a los supuestos que debe cumplir.


### Diagnóstico del modelo de Mincer "enriquecido"

```{r}
#Uso augment para calcular las variables necesarios para hacer los gráficos con ggplot
datos_augmentados <- augment(modelo_mincer2)

g1 = ggplot(datos_augmentados, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(datos_augmentados, aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(datos_augmentados, aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(datos_augmentados, aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```

Residuos vs valores predichos: en este caso se observa que los valores están centrados en cero, cunmpliendo uno de los supuestos.

Normal Q-Q plot: los valores siguen desviándose de la normal en los extremos, pero mejorar notablemente con respecto a los modelos anteriores.

Residuos vs leverage: siguen siendo todos menores a 0,5, por lo tanto ningún datos tiene una influencia mayor en el modelo.

Por lo tanto, este modelo es mas confiable que el del Mincer "sin enriquecer".


## Primer Modelo Propio

El objetivo de este modelo es ver la variación de salario por hora según la región en la cual habita el trabajador, teniendo en cuenta los años de educación y la experiencia potencial.

[ln(SalarioHorario)] = β0 + β1AñosEducacion + β2ln(Experiencia Potencial) + β3Region

Cabe aclarar que existen valores de Experiencia potencial iguales a cero, al ser imposible calcular el ln de esos valores, se decide eliminarlos.

### Evaluación del primero modelo propio

```{r}
#5)Modelos propios y evaluacion----

datos0 <- subset(datos, experiencia_potencial != 0)

#Modelo propio 1----
modelo_propio1 <- lm(formula = log(salario_horario) ~ educacion + log(experiencia_potencial)  +
                                         region ,
                                   data = datos0)
summary(modelo_propio1)
```

En este modelo la significancia individual de todos los coeficientes de las variables numéricas son significativos. 

Aumentar 1 año la educacion aumenta un 8,6% el salario por hora y aumentar un 1% la experiencia potencial aumenta un 0,15% el salario por hora.

Se realiza un ANOVA para ver la significancia de las variables categóricas

```{r}
tidy(anova(modelo_propio1))
```

El p-valor es menor a 0,05, por lo tanto la variable categórica es significativa para explicar la variación del salario por hora.

El modelo está referenciado a la región de Cuyo, por lo tanto podemos decir que los salario por hora de las otras regiones con respecto a Cuyo se comportan de la siguiente manera:
```{r}
resumen <- summary(modelo_propio1)
cat("Gran Buenos Aires: ", round(resumen$coefficients[4]*100,2),"% por encima")
```
```{r}
cat("Noreste: ", round(resumen$coefficients[5]*100,2),"% por debajo")
```
```{r}
cat("Noroeste: ", round(resumen$coefficients[6]*100,2),"% por debajo")
```
```{r}
cat("Pampeana: ", round(resumen$coefficients[7]*100,2),"% por encima")
```
```{r}
cat("Patagonia: ", round(resumen$coefficients[8]*100,2),"% por encima")
```

### Diagnóstico del primero modelo propio

Se realizan los gráficos correspondientes 

```{r}
#Uso augment para calcular las variables necesarios para hacer los gráficos con ggplot
datos_augmentados <- augment(modelo_propio1)

g1 = ggplot(datos_augmentados, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(datos_augmentados, aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(datos_augmentados, aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(datos_augmentados, aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```

Residuos vs valores predichos: evidencia una distribución centrada en cero.

Normal Q-Q plot: hacia los extremos se desvía un poco de la normalidad

Residuos vs leverage: no presenta valores da alto leverage.

```{r}
# para ejecutar el anti-log usamos función exponencial
eval2 <- broom::augment(modelo_propio1, datos0)
eval2 = eval2 %>%  mutate(fitted_antilog = exp(.fitted))
# calculamos RMSE y R2 para las variables originales y no log(price) para que sea comparable con los demás modelos
metricas2 = metrics(data = eval2, truth = salario_horario, estimate = fitted_antilog) %>% mutate(.estimate = round(.estimate, 4))
rcuadrado <- metricas2$.estimate[2]
cat("R-cuadrado = ", rcuadrado)
```
El modelo explica un 21,43% de la variabilidad total.


## Segundo Modelo Propio

El objetivo de este modelo es ver la variación de salario por hora según el tipo de establecimiento laboral en el cual trabajo la persona, teniendo en cuenta los años de educación y la experiencia potencial.

[ln(SalarioHorario)] = β0 + β1AñosEducacion + β2ln(Experiencia Potencial) + β3Tipo de establecimiento laboral

Nuevamente, existen valores de Experiencia potencial iguales a cero, al ser imposible calcular el ln de esos valores, se decide eliminarlos.

```{r}
#Modelo propio 2----
modelo_propio2 <- lm(formula = log(salario_horario) ~ educacion + log(experiencia_potencial) +
                                         tipo_establecimiento ,
                                   data = datos0)
summary(modelo_propio2)
```

En este modelo la significancia individual de todos los coeficientes de las variables numéricas son significativos. 

Aumentar 1 año la educacion aumenta un 7,7% el salario por hora y aumentar un 1% la experiencia potencial aumenta un 0,14% el salario por hora.

Se realiza un ANOVA para ver la significancia de las variables categóricas

```{r}
tidy(anova(modelo_propio2))
```

El p-valor es menor a 0,05, por lo tanto la variable categórica es significativa para explicar la variación del salario por hora.

El modelo está referenciado a el tipo de establecimiento estatal, por lo tanto podemos decir que los salario por hora de los otros tipos de establecimiento con respecto al estatal se comportan de la siguiente manera:

```{r}
resumen <- summary(modelo_propio2)
cat("Privado: ", round(resumen$coefficients[5]*100,2),"% por debajo")
```
```{r}
cat("Otro: ", round(resumen$coefficients[4]*100,2),"% por debajo")
```

### Diagnóstico del primero modelo propio

Se realizan los gráficos correspondientes

```{r}
#Uso augment para calcular las variables necesarios para hacer los gráficos con ggplot
datos_augmentados <- augment(modelo_propio2)

g1 = ggplot(datos_augmentados, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(datos_augmentados, aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(datos_augmentados, aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(datos_augmentados, aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```

Residuos vs valores predichos: evidencia una distribución centrada en cero.

Normal Q-Q plot: hacia los extremos se desvía un poco de la normalidad

Residuos vs leverage: no presenta valores da alto leverage.

```{r}
# para ejecutar el anti-log usamos función exponencial
eval3 <- broom::augment(modelo_propio2, datos0)
eval3 = eval3 %>%  mutate(fitted_antilog = exp(.fitted))
# calculamos RMSE y R2 para las variables originales y no log(price) para que sea comparable con los demás modelos
metricas3 = metrics(data = eval3, truth = salario_horario, estimate = fitted_antilog) %>% mutate(.estimate = round(.estimate, 4))
rcuadrado <- metricas3$.estimate[2]
cat("R-cuadrado = ", rcuadrado)
```

El modelo explica un 18,84% de la variabilidad total.

## Evaluación de los diferentes modelos vistos

Se comparan los 

```{r}
#testeo----
test <- read.csv("eph_test_2023.csv")

pred_modelo_propio1 <- augment(modelo_propio1, newdata = datos)
pred_modelo_propio1$exp_fitted <- exp(pred_modelo_propio1$.fitted)

pred_modelo_mincer1 <- augment(modelo_mincer1, newdata = datos)

pred_modelo_mincer2 <- augment(modelo_mincer2, newdata = datos)
pred_modelo_mincer2$exp_fitted <- exp(pred_modelo_mincer2$.fitted)

pred_modelo_propio2 <- augment(modelo_propio2, newdata = datos)
pred_modelo_propio2$exp_fitted <- exp(pred_modelo_propio2$.fitted)


library(janitor)
# Calcular las métricas
metrics <- tibble(
  Model = c("Modelo Propio 1", "Modelo Lineal Multiple", "Modelo Mincer", "Modelo Propio 2"),
  RMSE = c(
    rmse(data = pred_modelo_propio1, truth = salario_horario, estimate = exp_fitted)$.estimate,
    rmse(data = pred_modelo_mincer1, truth = salario_horario, estimate = .fitted)$.estimate,
    rmse(data = pred_modelo_mincer2, truth = salario_horario, estimate = exp_fitted)$.estimate,
    rmse(data = pred_modelo_propio2, truth = salario_horario, estimate = exp_fitted)$.estimate
  ),
  MAE = c(
    mae(data = pred_modelo_propio1, truth = salario_horario, estimate = exp_fitted)$.estimate,
    mae(data = pred_modelo_mincer1, truth = salario_horario, estimate = .fitted)$.estimate,
    mae(data = pred_modelo_mincer2, truth = salario_horario, estimate = exp_fitted)$.estimate,
    mae(data = pred_modelo_propio2, truth = salario_horario, estimate = exp_fitted)$.estimate
  )
)

# Opcional: Limpiar los nombres de las columnas
metrics <- clean_names(metrics)

# Mostrar la tabla
print(metrics)
```

```{r}
#testeo----
test <- read.csv("eph_test_2023.csv")

pred_modelo_propio1 <- augment(modelo_propio1, newdata = test)
pred_modelo_propio1$exp_fitted <- exp(pred_modelo_propio1$.fitted)

pred_modelo_mincer1 <- augment(modelo_mincer1, newdata = test)

pred_modelo_mincer2 <- augment(modelo_mincer2, newdata = test)
pred_modelo_mincer2$exp_fitted <- exp(pred_modelo_mincer2$.fitted)

pred_modelo_propio2 <- augment(modelo_propio2, newdata = test)
pred_modelo_propio2$exp_fitted <- exp(pred_modelo_propio2$.fitted)

library(janitor)
# Calcular las métricas
metrics <- tibble(
  Model = c("Modelo Propio 1", "Modelo Lineal Multiple", "Modelo Mincer 2", "Modelo Propio"),
  RMSE = c(
    rmse(data = pred_modelo_propio1, truth = salario_horario, estimate = exp_fitted)$.estimate,
    rmse(data = pred_modelo_mincer1, truth = salario_horario, estimate = .fitted)$.estimate,
    rmse(data = pred_modelo_mincer2, truth = salario_horario, estimate = exp_fitted)$.estimate,
    rmse(data = pred_modelo_propio2, truth = salario_horario, estimate = exp_fitted)$.estimate
  ),
  MAE = c(
    mae(data = pred_modelo_propio1, truth = salario_horario, estimate = exp_fitted)$.estimate,
    mae(data = pred_modelo_mincer1, truth = salario_horario, estimate = .fitted)$.estimate,
    mae(data = pred_modelo_mincer2, truth = salario_horario, estimate = exp_fitted)$.estimate,
    mae(data = pred_modelo_propio2, truth = salario_horario, estimate = exp_fitted)$.estimate
  )
)

# Opcional: Limpiar los nombres de las columnas
metrics <- clean_names(metrics)

# Mostrar la tabla
print(metrics)
```

De todos los modelos planteados hasta este momento el mejor a la hora de predecir el salario por hora de los trabajadores es el Modelo Propio 1 que tiene en cuenta la Región en la cual desempeñan sus tareas los trabajadores, ya que las métricas de RMSE y MAE son las menores en comparación con los otros modelos.

## Modelo Lineal Robusto

Se plantea un modelo lineal robusto con la misma configuración que el Modelo Lineal Múltiple.

Para entrenar este modelo y re-entrenar el Modelo Lineal mútiple y el Modelo de Mincer se utilzaron datos cuya variable salario por hora tiene outliers.

En los Boxplots que se grafican a continuación se puede ver la distribución de los datos con y sin outliers.

```{r}
# cargo datos train con outliers

train <- read.csv("eph_train_outliers_2023.csv")
train <- train[-c(2,3,6)]

datos$tipo <- "sin_outliers"
train$tipo <- "con_outliers"
prueba <- rbind(datos, train)

ggplot(data = prueba, aes(y = salario_horario, group = tipo, fill = tipo)) +
  geom_boxplot() + 
  scale_fill_brewer(palette="Dark2") +
  theme_bw() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  labs(title = "Boxplots de salario por hora trabajada", subtitle = "En pesos") +
  labs(y = "Salario por hora en pesos") +
  labs(x = "") +
  facet_wrap(~tipo)
```

Se entrenan los 3 modelos y se obtienen los siguientes resultados para cada uno de ellos

```{r}
modelo_multiple_outliers <- lm(formula = salario_horario ~ educacion + 
                       experiencia_potencial + 
                       I(experiencia_potencial^2) +
                       sexo +
                       sexo*educacion,
                     data=train)
summary(modelo_multiple_outliers, conf.int = T)
```

```{r}
modelo_mincer_outliers <- lm(formula = log(salario_horario) ~ educacion + 
                                experiencia_potencial + 
                                I(experiencia_potencial^2) +
                                sexo +
                                sexo:educacion,
                            data=train)
summary(modelo_mincer_outliers)
```

```{r}
modelo_multiple_robusto_outliers <- lmrob(formula = salario_horario ~ educacion + 
                       experiencia_potencial + 
                       I(experiencia_potencial^2) +
                       sexo +
                       sexo*educacion,
                     data=train)
resumen_rob <- summary(modelo_multiple_robusto_outliers)
cat("Call:")
```
```{r}
resumen_rob$call
```
```{r}
cat("Coefficients:")
```
```{r}
resumen_rob$coefficients
```
```{r}
cat("Robust residual standard error:", resumen_rob$sigma)
```
```{r}
cat("Multiple R-sqared: ", resumen$r.squared)
```
```{r}
cat("Adjusted R-squared: ", resumen$adj.r.squared)
```



```{r}
modelo_mincer_outliers <- lm(formula = log(salario_horario) ~ educacion + 
                                experiencia_potencial + 
                                I(experiencia_potencial^2) +
                                sexo +
                                sexo:educacion,
                            data=train)
summary(modelo_mincer_outliers)
```


En principio observamos que el error residual estándar del modelo lineal múltiple robusto es menor que el del modelo lineal múltiple, con lo cual ya podemos inferir que este será mejor en la predicción de la variable salario por hora.

```{r}
multiple <- summary(modelo_multiple_outliers)
cat("RSE Modelo lineal múltiple: ", multiple$sigma)
```

```{r}
cat("RSE Modelo lineal múltiple robusto: ", resumen_rob$sigma)
```

Ahora miremos las métricas de los coeficientes.

```{r}
# armamos lista con todos los modelos
models <- list(modelo_multiple_robusto_outliers = modelo_multiple_robusto_outliers, 
               modelo_multiple_outliers = modelo_multiple_outliers)
# calculamos las variables resumen
map_df(models, tidy, .id = "model")
```

En el modelo lineal multiple robusto no se calcular los p-valores ya que este modelaje no usa los supuestos de distribucion normal centrada en cero y homocedasticidad.

Para comparar la significancia individual de los coeficientes utilizamos el error estándar de cada uno de ellos, donde se observa que en el modelo robusto estos errores son mucho menores que el no robusto.

```{r}
tidy(anova(modelo_multiple_robusto_outliers))
```

```{r}
pred_modelo_multiple_outliers <- augment(modelo_multiple_outliers, newdata = train)

pred_modelo_multiple_robusto_outliers <- augment(modelo_multiple_robusto_outliers, newdata = train)

pred_mmodelo_mincer_outliers <- augment(modelo_mincer_outliers, newdata = train)
pred_mmodelo_mincer_outliers$exp_fitted <- exp(pred_mmodelo_mincer_outliers$.fitted)


# Calcular las métricas
metrics <- tibble(
  Model = c("Modelo Múltiple", "Modelo Múltiple Robusto", "Modelo Mincer"),
  RMSE = c(
    rmse(data = pred_modelo_multiple_outliers, truth = salario_horario, estimate = .fitted)$.estimate,
    rmse(data = pred_modelo_multiple_robusto_outliers, truth = salario_horario, estimate = .fitted)$.estimate,
    rmse(data = pred_mmodelo_mincer_outliers, truth = salario_horario, estimate = exp_fitted)$.estimate
  ),
  MAE = c(
    mae(data = pred_modelo_multiple_outliers, truth = salario_horario, estimate = .fitted)$.estimate,
    mae(data = pred_modelo_multiple_robusto_outliers, truth = salario_horario, estimate = .fitted)$.estimate,
    mae(data = pred_mmodelo_mincer_outliers, truth = salario_horario, estimate = exp_fitted)$.estimate
  )
)

# Opcional: Limpiar los nombres de las columnas
metrics <- clean_names(metrics)

# Mostrar la tabla
print(metrics)
```



```{r}
pred_modelo_multiple_outliers <- augment(modelo_multiple_outliers, newdata = test)

pred_modelo_multiple_robusto_outliers <- augment(modelo_multiple_robusto_outliers, newdata = test)

pred_mmodelo_mincer_outliers <- augment(modelo_mincer_outliers, newdata = test)
pred_mmodelo_mincer_outliers$exp_fitted <- exp(pred_mmodelo_mincer_outliers$.fitted)

# Calcular las métricas
metrics <- tibble(
  Model = c("Modelo Múltiple", "Modelo Múltiple Robusto", "Modelo Mincer"),
  RMSE = c(
    rmse(data = pred_modelo_multiple_outliers, truth = salario_horario, estimate = .fitted)$.estimate,
    rmse(data = pred_modelo_multiple_robusto_outliers, truth = salario_horario, estimate = .fitted)$.estimate,
    rmse(data = pred_mmodelo_mincer_outliers, truth = salario_horario, estimate = exp_fitted)$.estimate
  ),
  MAE = c(
    mae(data = pred_modelo_multiple_outliers, truth = salario_horario, estimate = .fitted)$.estimate,
    mae(data = pred_modelo_multiple_robusto_outliers, truth = salario_horario, estimate = .fitted)$.estimate,
    mae(data = pred_mmodelo_mincer_outliers, truth = salario_horario, estimate = exp_fitted)$.estimate
  )
)

# Opcional: Limpiar los nombres de las columnas
metrics <- clean_names(metrics)

# Mostrar la tabla
print(metrics)
```

Con respetco al error cuadrático médio, el modelo lineal múltiple parecería tener un mejor desempeño, sin embargo no parecería haber apreciarse si hay una real mejor desempeño de este modelo con respecto a lso otros dos.

Como el error cuadrático medio penaliza mas la diferencia entre los datos, quizás es mejor utilizar Error absoluto medio (MAE), ya que penaliza menos la presencia de outliers y en este caso estamos utilizando un modelo robusto que en si mismo ya maneja este tipo de datos de mejor manera que los tradicionales.

Se observa que los resultados de MAE mejoran cuando pasamos del Modelo lineal mútiple tradicional al Modelo Lineal Múltiple Robusto, apreciandose como este modelo puede manejar mejor los outliers.

Sin embargo, el mejor modelo parece seguir siendo el Lineal Multiple de Mincer donde trabajar con escala logarítmica la variable a predecir logrando aaproximarse a los supuestos de un modelo lineal múltiple sería la mejor opción.


